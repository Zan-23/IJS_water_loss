{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Presentation of gathered results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import math\n",
    "import pandas as pandas\n",
    "from pandas import concat\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "from statistics import mean\n",
    "from numpy.random import shuffle\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pandas.read_json(\"../data/water_loss_data_set_1.json\")\n",
    "data = data[(data.timeStamp != \"0000-00-00 00:00:00\" ) & (data.timeStamp != \"2000-01-01 00:00:00\")]\n",
    "data = data[(data.tot1 != 0 ) & (data.analog2 != 0)]\n",
    "data[\"timeStamp\"] = pandas.to_datetime(data[\"timeStamp\"], format=\"%Y-%m-%d %H:%M\")\n",
    "\n",
    "data_with_minutes = data.copy(deep=True)\n",
    "\n",
    "# Normalisation of pressure data\n",
    "# data[\"analog2\"] = ((data[\"analog2\"] - data[\"analog2\"].min()) / (data[\"analog2\"].max() - data[\"analog2\"].min()))\n",
    "\n",
    "data_249_min = data[data['idflowmeter'] == \"MAG8000_024905H318\"]\n",
    "data_248_min = data[data['idflowmeter'] == \"MAG8000_024805H318\"]\n",
    "data_249_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_sel_time(start, end, data_fun):\n",
    "    return data_fun.loc[(data_fun[\"timeStamp\"] >= start) & (data_fun[\"timeStamp\"] <= end)]   \n",
    "\n",
    "def derivate(x_data, y_data):\n",
    "    x_arr = []\n",
    "    y_arr = []\n",
    "    derivate_y = np.diff(y_data, n=2) # second derivative\n",
    "    idx_max_dy = np.argmax(derivate_y)\n",
    "\n",
    "    \"\"\"    # initialize N  \n",
    "    N = 20  # Indices of N largest elements in list \n",
    "    res = sorted(range(len(derivate_y)), key = lambda sub: derivate_y[sub])[-N:][::-1] \"\"\"\n",
    "    # print(sorted(set(derivate_y)))\n",
    "    \n",
    "    for index, value in enumerate(derivate_y):\n",
    "        if abs(value) >= 0.05:\n",
    "            # print(np.datetime_as_string(x_data[index], unit='m'), \" value:\", y_data[index])\n",
    "            x_arr.append(x_data[index])\n",
    "            y_arr.append(y_data[index])\n",
    "    \n",
    "    return x_arr, y_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of all data with an option to zoom on specific part \n",
    "\n",
    "List of dates where an anomaly occurs:\n",
    "- 24.1.2019 7.27\n",
    "- 25.1.2019 6.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# anomaly_rows_248 = data_248_min.loc[(data_248_min['analog2'] <= 0.72)]\n",
    "data_249_processed = data_sel_time(\"2018-11-28 08:00:00\", \"2020-06-26 08:00:00\", data_249_min)\n",
    "anomaly_rows_249 = data_249_processed.loc[(data_249_processed['analog2'] <= 0.72)]\n",
    "dates_249 = anomaly_rows_249[\"timeStamp\"].map(pandas.Timestamp.date).unique()\n",
    "dates_249 = [i.strftime(\"%d-%m-%Y\") for i in dates_249]\n",
    "\n",
    "with pandas.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(dates_249)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph with visualization of all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_sel_time(\"2018-11-20 08:00:00\", \"2020-06-26 08:00:00\", data_249_min)\n",
    "x = df[\"timeStamp\"].values\n",
    "y = df[\"analog2\"].values\n",
    "# print(x)\n",
    "\n",
    "\"\"\"fig = px.line(df, x=\"timeStamp\", y=\"analog2\", height=600)\n",
    "fig.show()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph with criticical points they are only determined after an anomaly already happends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_d, y_d = derivate(x, y)\n",
    "\n",
    "\"\"\"\n",
    "# With \"critical points\"\n",
    "fig = go.Figure()\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=y))\n",
    "fig.add_trace(go.Scatter(x=x_d, y=y_d, mode='markers', name='markers'))\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prasi kaj je blo za te datume:  \n",
    "['09-01-2019', '10-01-2019', '13-01-2019', '24-01-2019', '25-01-2019', '26-01-2019', '12-03-2019', '31-03-2019', '04-04-2019', '05-04-2019', '09-04-2019', '14-04-2019', '15-04-2019', '17-04-2019', '27-04-2019', '04-05-2019', '06-05-2019', '12-05-2019', '13-05-2019', '14-05-2019', '15-05-2019', '01-06-2019', '05-06-2019', '08-06-2019', '10-06-2019', '12-06-2019', '13-06-2019', '15-06-2019', '17-06-2019', '18-06-2019', '19-06-2019', '22-06-2019', '24-06-2019', '03-08-2019', '28-08-2019', '30-09-2019', '03-10-2019', '31-10-2019', '27-11-2019', '18-12-2019', '30-12-2019', '08-01-2020', '05-02-2020', '27-02-2020']\n",
    "  \n",
    "   \n",
    "Also kaj je blo med 24.1.2019 in 4.2.2019 in med aprilom in oktobrom v obeh primerih so vrhi nizji. Poglej si Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://scikit-learn.org/stable/auto_examples/ensemble/plot_isolation_forest.html\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "rng = np.random.RandomState(42)\n",
    "\n",
    "# Generate train data\n",
    "X = 0.3 * rng.randn(100, 2)\n",
    "X_train = np.r_[X + 2, X - 2]\n",
    "# Generate some regular novel observations\n",
    "X = 0.3 * rng.randn(20, 2)\n",
    "X_test = np.r_[X + 2, X - 2]\n",
    "# Generate some abnormal novel observations\n",
    "X_outliers = rng.uniform(low=-4, high=4, size=(20, 2))\n",
    "\n",
    "# fit the model\n",
    "clf = IsolationForest(max_samples=100, random_state=rng)\n",
    "clf.fit(X_train)\n",
    "y_pred_train = clf.predict(X_train)\n",
    "y_pred_test = clf.predict(X_test)\n",
    "y_pred_outliers = clf.predict(X_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=y,\n",
    "                    mode='lines+markers',\n",
    "                    name='lines+markers'))\n",
    "\n",
    "fig.show()\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
